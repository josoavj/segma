# Configuration du Mod√®le SAM

## üéØ Nouveaux Endpoints

### 1. Obtenir les informations du mod√®le
```bash
GET /api/v1/model/info
```

**R√©ponse:**
```json
{
  "model_type": "vit_b",
  "device": "cpu",
  "is_loaded": true,
  "available_models": ["vit_b", "vit_l", "vit_h"],
  "cuda_available": false
}
```

---

### 2. Changer le mod√®le ou le device
```bash
POST /api/v1/model/change
Content-Type: application/json

{
  "model_type": "vit_l",
  "device": "cuda"
}
```

**Param√®tres:**
- `model_type` (string, requis): Type de mod√®le
  - `vit_b`: Petit mod√®le (~96MB), rapide, pour CPU
  - `vit_l`: Mod√®le interm√©diaire (~312MB), pr√©cis
  - `vit_h`: Grand mod√®le (~1.2GB), tr√®s pr√©cis
  
- `device` (string, optionnel): Processeur
  - `cpu`: Processeur central
  - `cuda`: GPU NVIDIA

**R√©ponse:**
```json
{
  "status": "success",
  "model_type": "vit_l",
  "device": "cuda",
  "is_loaded": true,
  "available_models": ["vit_b", "vit_l", "vit_h"],
  "cuda_available": true
}
```

---

## üìä Temps de Chargement Estim√©

| Mod√®le | RAM | Temps (CPU) | Temps (GPU) |
|--------|-----|------------|------------|
| **vit_b** | ~380MB | 2-3s | 1s |
| **vit_l** | ~1.2GB | 5-10s | 2-3s |
| **vit_h** | ~2.5GB | 15-30s | 5-10s |

---

## üöÄ Cas d'Usage

### Configuration Rapide (Temps r√©el)
```json
{
  "model_type": "vit_b",
  "device": "cpu"
}
```
‚úÖ Id√©al pour le prototypage et les tests
‚ö†Ô∏è Moins pr√©cis

### Configuration Balanc√©e
```json
{
  "model_type": "vit_l",
  "device": "cpu"
}
```
‚úÖ Bon √©quilibre vitesse/pr√©cision
‚ö†Ô∏è Requiert ~1.2GB RAM

### Configuration Pr√©cise
```json
{
  "model_type": "vit_h",
  "device": "cuda"
}
```
‚úÖ R√©sultats tr√®s pr√©cis
‚ö†Ô∏è Requiert GPU et 2.5GB VRAM

---

## üîÑ Variables d'Environnement

Dans `.env`:
```bash
# Mod√®le par d√©faut au d√©marrage
SAM_MODEL_TYPE=vit_b

# Device par d√©faut
DEVICE=cpu
```

---

## üí° Am√©lioration de la Segmentation

Le nouvel algorithme utilise:

1. **Grille multi-densit√©**: 
   - Grille 8x8 pour les objets standards
   - Grille 12x12 pour les petits objets

2. **D√©duplication intelligente**:
   - D√©tecte les masques dupliqu√©s par IoU
   - Seuil: 70% d'IoU

3. **Filtrage par taille**:
   - Minimum: 30 pixels (capte les petits objets)
   - Maximum: 95% de l'image (√©vite tout l'image)

4. **D√©tection YOLO am√©lior√©e**:
   - Labels en anglais automatiques
   - Matching IoU pour chaque objet

---

## üìù Exemples Complets

### Changer vers vit_l sur CPU
```bash
curl -X POST http://localhost:8000/api/v1/model/change \
  -H "Content-Type: application/json" \
  -d '{
    "model_type": "vit_l",
    "device": "cpu"
  }'
```

### Changer vers vit_h sur GPU
```bash
curl -X POST http://localhost:8000/api/v1/model/change \
  -H "Content-Type: application/json" \
  -d '{
    "model_type": "vit_h",
    "device": "cuda"
  }'
```

### V√©rifier la configuration actuelle
```bash
curl http://localhost:8000/api/v1/model/info
```

---

## ‚ö†Ô∏è Notes Importantes

1. **Changement de mod√®le**: Les requ√™tes pendant le changement attendront la fin du chargement
2. **CUDA**: Disponible uniquement si PyTorch CUDA est install√©
3. **M√©moire**: V√©rifiez que votre syst√®me a assez de RAM/VRAM
4. **Premi√®re utilisation**: Chaque mod√®le t√©l√©charge ses poids la premi√®re fois (~1-2 minutes)

